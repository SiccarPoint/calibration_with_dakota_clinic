{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals of this Clinic\n",
    "\n",
    "The scope of both calibration and [Dakota](https://dakota.sandia.gov) are large. This two-hour clinic was designed to deliver the following information. \n",
    "- Conceptual introduction to calibration and a discussion of some of the major options in calibration methods. \n",
    "- Introduction to the [Dakota](https://dakota.sandia.gov) package. \n",
    "- Background for a simple example using data from [Clow (2014)]() and a simple model of 1D heat diffusion. \n",
    "- Experience with a simple example in Dakota --- including understanding how you must set up your model so Dakota can run it, and what files Dakota uses and makes. \n",
    "- Knowledge of what User Guides and resourses are available to further your knowledge.\n",
    "\n",
    "\n",
    "# Step 1: Introduction to calibration\n",
    "\n",
    "## What is calibration/optimization/parameter estimation?\n",
    "\n",
    "- General definition\n",
    "\n",
    "- black box model (parameters > model > outputs)\n",
    "- parameters and outputs must be formally defined.\n",
    "\n",
    "## Some useful definitions\n",
    "\n",
    "- gradient based vs global\n",
    "- single vs multi-objective\n",
    "- complex model vs statistical surogate\n",
    "- a method that provides parameter uncertainty or just best parameter set (linear vs. nonlinear assumptions)\n",
    "- constrained vs unconstrained\n",
    "- smoothness of objetive function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Problem statement and dataset\n",
    "\n",
    "Today's clinic will use a model of 1D diffusion of heat in the Earth's crust and data from [Clow (2014)](https://www.earth-syst-sci-data.net/6/201/2014/essd-6-201-2014.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(\"resources\", \"clow_2014\", \"G10015\", \"AWU*.txt\"))\n",
    "dfs = []\n",
    "for path in files:\n",
    "    date = os.path.split(path)[-1].split(\".\")[0].split(\"_\")[-1]\n",
    "    site = os.path.split(path)[-1].split(\".\")[0].split(\"_\")[0]\n",
    "    year = int(date[:2])\n",
    "    if year<19:\n",
    "        year += 2000\n",
    "    else:\n",
    "        year += 1900\n",
    "    tdf = pd.read_csv(path, header=22, skip_blank_lines=False, sep=\"\\s+\")\n",
    "    tdf[\"Date\"] = date\n",
    "    tdf[\"Year\"] = year\n",
    "    tdf[\"Site\"] = site\n",
    "    dfs.append(tdf)\n",
    "df = pd.concat(dfs).sort_values([\"Site\", \"Date\", \"Depth\"]).reset_index(drop=True)\n",
    "\n",
    "(ggplot(df, aes(x=\"Temperature\", y=\"Depth\", color=\"factor(Year)\")) +\n",
    " geom_path(na_rm=True) + \n",
    " facet_wrap(\"~Site\") +\n",
    " scale_y_reverse())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model, parameters and objective function.\n",
    "\n",
    "- diffusion of heat + surface temperature history\n",
    "- OF based on fitting Clow paper data using an RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Introduction to Dakota\n",
    "\n",
    "[Dakota](https://dakota.sandia.gov)\n",
    "\n",
    "[Online Documentation](https://dakota.sandia.gov/content/69-reference-manual)\n",
    "\n",
    "[PDFs to download](https://dakota.sandia.gov/content/manuals)\n",
    "\n",
    "- Dakota has more bells and whistles, it is well thought out, and the\n",
    "  documentation is quite good. Its just extensive and not an iPhone.\n",
    "- Dakota has a gui if your into that.\n",
    "- There are lots of hierarchical type things you can do.\n",
    "- Restart utility, deprepro, and pyprepro....\n",
    "- Core activity (assuming you have a black box model set up) is to create and\n",
    "  run an input file.\n",
    "- Dakota then iteratively runs your model for you to determine parameter values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will do:\n",
    "- Look at .in file.\n",
    "    * discuss each part\n",
    "- Look at template file and driver.py (connect this with black box parts)\n",
    "- Run Dakota, create plots, look at output.\n",
    "- Discuss Dakota's file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat analysis/dakota_01_grid.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat analysis/template_dir/driver.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat analysis/template_dir/input_template.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! dakota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat start_01_grid.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"analysis\")\n",
    "subprocess.call(\"./start_01_grid.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"MULTIDIM_PARAM\")\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"run.1\")\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat params.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat inputs.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat results.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go look at the file strucure. \n",
    "\n",
    "look at output make point about reproduciblity and .rst file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! cat dakota_01_grid.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other methods\n",
    "We just did a brute force grid search. This is sort of an optimization.\n",
    "Next we will do a gradient based method and a global method.\n",
    "\n",
    "What's different about their input files. \n",
    "- Gradients  are necessary for NL2SOL\n",
    "- Seed is necessary for EGO (or a default is used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "! cat dakota_02_nl2sol.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat dakota_03_ego.in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subprocess.call(\"./start_02_nl2sol.sh\")\n",
    "subprocess.call(\"./start_03_ego.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"*.dat\")\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, engine=\"python\", sep=\"\\s+\")\n",
    "    df[\"method\"] = file.split('.')[0].split(\"_\")[-1]\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "method_cats = CategoricalDtype(categories=[\"grid\", \n",
    "                                           \"nl2sol\", \n",
    "                                           \"ego\"], \n",
    "                               ordered=True)\n",
    "df[\"method\"] = df[\"method\"].astype(method_cats)\n",
    "df = df.set_index([\"method\", \"T\", \"duration_years\"]).drop(columns=[\"interface\"])\n",
    "\n",
    "# plot evaluations\n",
    "(ggplot(df.reset_index(), aes(x=\"T\", y=\"duration_years\", color=\"%eval_id\")) + \n",
    "     geom_point() + \n",
    "     scale_color_cmap(name='jet') +\n",
    "     facet_wrap(\"~method\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(ggplot(df.reset_index(), aes(x=\"T\", y=\"duration_years\", color=\"rmse\")) + \n",
    "     geom_point() + \n",
    "     facet_wrap(\"~method\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how results and number of evaluations are influenced by method\n",
    "sum_df = df.drop(columns=[\"%eval_id\"]).groupby(\"method\").agg([np.count_nonzero, np.min])\n",
    "sum_df.columns = sum_df.columns.map('|'.join).str.strip('|')\n",
    "\n",
    "(ggplot(sum_df.reset_index(), (aes(x=\"rmse|count_nonzero\", y=\"rmse|amin\", color=\"method\"))) + geom_point())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summarized best Ts and durations\n",
    "best_df=df[df.rmse.isin(sum_df[\"rmse|amin\"].values)].reset_index()\n",
    "print(best_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion:\n",
    "- computational cost of Dakota method vs complex model evaluation.\n",
    "    * calculation of numerical gradients\n",
    "    * increasing dimension\n",
    "- do you need parameter estimates, or just a best fit point.\n",
    "- RST file, .out file and reproducible research\n",
    "- We haven't yet talked about the uncertainty estimates on  parameters, just\n",
    "  which parameter is best. That is for another day.\n",
    "\n",
    "# Exploration if time:\n",
    "* Explore other optimization methods. Start by going to the [Online Reference Manual](https://dakota.sandia.gov/content/69-reference-manual) and selecting Topics Area > Methods > Optimization and Calibration\n",
    "* Add a second component of the objective function.\n",
    "* Make the model (of surface temperature history) more complex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
